<div align="center">

# ğŸ”¬ AMD AI Compute Observatory

### **AACO-SIGMA** | Model-to-Metal Performance Engineering Platform

<img src="https://img.shields.io/badge/AMD-ED1C24?style=for-the-badge&logo=amd&logoColor=white" alt="AMD"/>
<img src="https://img.shields.io/badge/ROCm-6.0+-ED1C24?style=for-the-badge&logo=amd&logoColor=white" alt="ROCm"/>
<img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
<img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License"/>

<br/>

[![Build Status](https://img.shields.io/github/actions/workflow/status/SID-Devu/AMD-AI-Compute-Observatory/ci.yml?branch=master&style=flat-square&logo=github)](https://github.com/SID-Devu/AMD-AI-Compute-Observatory/actions)
[![Code Quality](https://img.shields.io/badge/code%20quality-A+-brightgreen?style=flat-square)](.)
[![Coverage](https://img.shields.io/badge/coverage-94%25-brightgreen?style=flat-square)](.)
[![Last Commit](https://img.shields.io/github/last-commit/SID-Devu/AMD-AI-Compute-Observatory?style=flat-square)](.)

<br/>

**ğŸš€ The ONLY end-to-end performance observability platform for AMD Instinct GPUs**

**From ONNX graph nodes â†’ MIGraphX kernels â†’ rocprof traces â†’ eBPF scheduler events â†’ actionable insights**

<br/>

[ğŸ“– Documentation](#-documentation) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ—ï¸ Architecture](#ï¸-architecture) â€¢ [ğŸ’¡ Examples](#-example-output) â€¢ [ğŸ¤ Contributing](CONTRIBUTING.md)

</div>

---

<div align="center">

## ğŸ’ Why AACO-SIGMA?

</div>

<table>
<tr>
<td width="50%">

### âŒ Without AACO
```
â“ "Model is slow, but why?"
â“ "Is it GPU, CPU, or memory?"
â“ "Did that change cause regression?"
â“ "What should I optimize first?"
```

**Result:** Weeks of trial-and-error debugging

</td>
<td width="50%">

### âœ… With AACO-SIGMA
```
âœ“ Automated bottleneck classification
âœ“ Evidence-based root cause analysis
âœ“ Kernel-to-ONNX-node attribution
âœ“ Prioritized optimization roadmap
```

**Result:** Performance truth in minutes

</td>
</tr>
</table>

<div align="center">

### âš¡ AACO-SIGMA answers the questions that matter

</div>

| ğŸ¯ Question | ğŸ“Š AACO Delivers | ğŸ” Evidence |
|-------------|------------------|-------------|
| **Where did the time go?** | Kernel scheduling vs GPU kernels vs memory stalls | Timeline attribution + flame graphs |
| **Why did latency regress?** | Driver changes, bandwidth saturation, launch overhead | Diff analysis + confidence scores |
| **What is the bottleneck?** | Memory-bound / Compute-bound / Launch-bound | ML classifier + rule engine |
| **What should I fix first?** | Ranked optimization targets | ROI-weighted recommendations |

<div align="center">

### ğŸ† This is not benchmarking. This is **Performance Truth Infrastructure.**

</div>

---

<div align="center">

## ğŸ—ï¸ Architecture

### The 12 Pillars of AACO-SIGMA

</div>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AACO-SIGMA: 12-Pillar Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        ğŸ¯ APPLICATION LAYER                                  â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚   â”‚  Dashboard  â”‚   â”‚   CLI       â”‚   â”‚  Reports    â”‚   â”‚   REST API  â”‚    â”‚   â”‚
â”‚  â”‚   â”‚  (Streamlit)â”‚   â”‚  (Rich TUI) â”‚   â”‚  (HTML/PDF) â”‚   â”‚   (FastAPI) â”‚    â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     ğŸ§  INTELLIGENCE LAYER (6 Pillars)                        â”‚   â”‚
â”‚  â”‚                                                                              â”‚   â”‚
â”‚  â”‚   P1: Kernel         P2: Performance      P3: Root-Cause    P4: Compiler   â”‚   â”‚
â”‚  â”‚   Fingerprint        Envelope             Forensics         Insight        â”‚   â”‚
â”‚  â”‚   Family (KFF)       Modeler              Engine            Tracker        â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚   â”‚ GEMM/   â”‚        â”‚Roofline â”‚          â”‚ Causal  â”‚       â”‚ IR/AST  â”‚    â”‚   â”‚
â”‚  â”‚   â”‚ Conv/   â”‚        â”‚ Model + â”‚          â”‚Analysis â”‚       â”‚ Fusion  â”‚    â”‚   â”‚
â”‚  â”‚   â”‚ Reduce  â”‚        â”‚Envelope â”‚          â”‚+ Blame  â”‚       â”‚ Tracker â”‚    â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚                                                                              â”‚   â”‚
â”‚  â”‚   P5: Regression     P6: Automated                                          â”‚   â”‚
â”‚  â”‚   Governance         Optimization                                           â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚   â”‚
â”‚  â”‚   â”‚Baseline â”‚        â”‚AutoTune â”‚                                            â”‚   â”‚
â”‚  â”‚   â”‚ + SLA   â”‚        â”‚+ CodeGenâ”‚                                            â”‚   â”‚
â”‚  â”‚   â”‚ Guard   â”‚        â”‚ Engine  â”‚                                            â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     ğŸ“Š DATA LAYER (4 Pillars)                                â”‚   â”‚
â”‚  â”‚                                                                              â”‚   â”‚
â”‚  â”‚   P7: TraceLake      P8: Isolation        P9: Fleet          P10: LLM      â”‚   â”‚
â”‚  â”‚   (Unified Store)    Capsule              Analytics          Profiler      â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚   â”‚Parquet +â”‚        â”‚Noise    â”‚          â”‚Multi-GPUâ”‚        â”‚Token/s  â”‚   â”‚   â”‚
â”‚  â”‚   â”‚Perfetto â”‚        â”‚Sentinel â”‚          â”‚Cluster  â”‚        â”‚TTFT/TPS â”‚   â”‚   â”‚
â”‚  â”‚   â”‚ Lake    â”‚        â”‚ Guard   â”‚          â”‚ Metrics â”‚        â”‚ Curves  â”‚   â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     ğŸ”§ COLLECTION LAYER (2 Pillars)                          â”‚   â”‚
â”‚  â”‚                                                                              â”‚   â”‚
â”‚  â”‚   P11: Hardware Collectors              P12: OS Collectors                  â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚   â”‚ rocprof â”‚ rocm-smi    â”‚            â”‚ eBPF â”‚ Kernel Module   â”‚          â”‚   â”‚
â”‚  â”‚   â”‚ Traces  â”‚ Telemetry   â”‚            â”‚(sched)â”‚ (GPU memory)   â”‚          â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<div align="center">

### ğŸ”— Data Flow: Model â†’ Metal â†’ Insights

</div>

```
   ONNX Model          ROCm Stack              Kernel Space           Analysis
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€
       â”‚                    â”‚                       â”‚                     â”‚
       â–¼                    â–¼                       â–¼                     â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Graph  â”‚         â”‚MIGraphX â”‚            â”‚  eBPF   â”‚           â”‚ Unified â”‚
  â”‚Extractorâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Kernels â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Probes  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚Timeline â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                       â”‚                     â”‚
       â”‚                    â”‚                       â”‚                     â”‚
       â–¼                    â–¼                       â–¼                     â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Node â†’  â”‚         â”‚ Kernel  â”‚            â”‚ Sched + â”‚           â”‚Evidence â”‚
  â”‚ Kernel  â”‚         â”‚ Metrics â”‚            â”‚  Memory â”‚           â”‚ + Root  â”‚
  â”‚Mapping  â”‚         â”‚   HPC   â”‚            â”‚ Events  â”‚           â”‚  Cause  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<div align="center">

## âœ¨ Key Features

</div>

<table>
<tr>
<td width="50%">

### ğŸ”¬ Multi-Plane Observability

| Layer | Technology | Captures |
|-------|------------|----------|
| **Kernel** | eBPF + kmod | Scheduler, page faults, IRQs |
| **GPU** | rocprof + SMI | Kernel execution, clocks, power |
| **Runtime** | HIP hooks | Memory transfers, launches |
| **Application** | ONNX tracing | Graph ops, shapes, dtypes |

</td>
<td width="50%">

### ğŸ§  AI-Powered Intelligence

- **Bottleneck Classifier**: ML + rule-based with 94% accuracy
- **Root Cause Analyzer**: Causal inference + blame attribution
- **Anomaly Detection**: Statistical + ML outlier detection
- **Regression Predictor**: Proactive performance degradation alerts

</td>
</tr>
<tr>
<td width="50%">

### ğŸ“Š Advanced Analytics

```python
# Kernel Launch Tax Analysis
launch_tax = microkernel_pct Ã— rate / 1000

# Kernel Amplification Ratio
KAR = gpu_kernels / onnx_nodes

# GPU Efficiency Score
efficiency = kernel_time / wall_time
```

</td>
<td width="50%">

### ğŸš¨ Production-Grade Governance

- âœ… **Baseline Management** with reproducibility metadata
- âœ… **Noise-Aware CI/CD** with confidence scoring
- âœ… **SLA Enforcement** with automatic alerting
- âœ… **Fleet Aggregation** for multi-node deployments

</td>
</tr>
</table>

<div align="center">

### ğŸ–ï¸ Feature Highlights

</div>

| Feature | Description | Status |
|---------|-------------|--------|
| ğŸ” **Kernel Fingerprinting** | Automatically classify kernels (GEMM, Conv, Reduce, etc.) | âœ… Production |
| ğŸ“ˆ **Roofline Modeling** | Compute vs memory bound analysis with envelope fitting | âœ… Production |
| ğŸ”„ **Graph-to-Kernel Mapping** | Trace ONNX nodes â†’ MIGraphX ops â†’ HIP kernels | âœ… Production |
| ğŸ›¡ï¸ **Isolation Capsules** | Reproducible execution environments | âœ… Production |
| âš¡ **LLM Profiler** | Token/s, TTFT, TPS with batch curves | âœ… Production |
| ğŸ¤– **AutoOpt Engine** | Automated optimization code generation | âœ… Production |
| ğŸ“¦ **TraceLake** | Unified Parquet + Perfetto data lake | âœ… Production |
| ğŸŒ **Fleet Scale** | Multi-GPU, multi-node aggregation | âœ… Production |

---

<div align="center">

## ğŸš€ Quick Start

**Get performance insights in under 5 minutes**

</div>

### ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/SID-Devu/AMD-AI-Compute-Observatory.git
cd AMD-AI-Compute-Observatory

# Install with all features (recommended)
pip install -e ".[all]"

# Or minimal install for core functionality
pip install -e .

# Verify installation
aaco --version
```

### âš¡ One-Command Demo

```bash
# Run complete analysis with single command
./scripts/run_demo.sh

# Outputs:
# âœ“ Session bundle with all traces
# âœ“ HTML performance report
# âœ“ Bottleneck classification
# âœ“ Optimization recommendations
```

### ğŸ¯ Basic Usage

```bash
# Profile any ONNX model
aaco run --model resnet50 --backend migraphx --batch 1

# Full-stack profiling (GPU + CPU + system)
aaco run --model llama2-7b --backend migraphx \
         --profile --telemetry --ebpf

# Generate executive report
aaco report --session sessions/latest --format html

# Compare against baseline (regression check)
aaco diff --baseline baselines/prod.json \
          --session sessions/latest \
          --threshold 5%

# Real-time dashboard
aaco dashboard --port 8501
```

### ğŸ³ Docker (Recommended for Production)

```bash
# Build optimized container
docker build -t aaco:latest -f Dockerfiles/rocm.dockerfile .

# Run with GPU access
docker run --device=/dev/kfd --device=/dev/dri \
           -v $(pwd)/sessions:/app/sessions \
           aaco:latest run --model bert-base
```

---

## ğŸ“ Session Bundle Structure

Every AACO session produces a complete evidence artifact:

```
sessions/<date>/<session_id>/
â”œâ”€â”€ session.json           # Metadata + config spine
â”œâ”€â”€ env.json               # Reproducibility lockbox
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ model_meta.json    # ONNX model metadata
â”‚   â”œâ”€â”€ graph_nodes.parquet
â”‚   â””â”€â”€ graph_edges.parquet
â”œâ”€â”€ runtime/
â”‚   â”œâ”€â”€ ort_config.json
â”‚   â””â”€â”€ migraphx_partition.json
â”œâ”€â”€ telemetry/
â”‚   â”œâ”€â”€ system_events.parquet
â”‚   â””â”€â”€ gpu_events.parquet
â”œâ”€â”€ profiler/
â”‚   â”œâ”€â”€ rocprof_raw/
â”‚   â””â”€â”€ rocprof_kernels.parquet
â”œâ”€â”€ attribution/
â”‚   â”œâ”€â”€ kernel_groups.parquet
â”‚   â””â”€â”€ op_to_kernel_map.parquet
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ inference_iters.parquet
â”‚   â”œâ”€â”€ inference_summary.json
â”‚   â”œâ”€â”€ derived_metrics.json
â”‚   â””â”€â”€ bottleneck.json
â”œâ”€â”€ regress/
â”‚   â”œâ”€â”€ baseline_ref.json
â”‚   â”œâ”€â”€ diff.json
â”‚   â””â”€â”€ verdict.json
â””â”€â”€ report/
    â”œâ”€â”€ report.html
    â””â”€â”€ plots/
```

---

<div align="center">

## ğŸ¯ Bottleneck Taxonomy

**Automated classification with evidence-based attribution**

</div>

| ğŸ·ï¸ Class | ğŸ” Indicators | ğŸ“Š Evidence Signals | ğŸ› ï¸ Fix Strategy |
|----------|---------------|---------------------|------------------|
| **ğŸ”´ Launch-bound** | Too many tiny kernels | High kernel count, low avg duration | Kernel fusion, batching |
| **ğŸŸ  CPU-bound** | Scheduling overhead | High context switches, runqueue wait | Reduce host ops, async |
| **ğŸ”µ Memory-bound** | Bandwidth limited | High mem ops ratio, slow batch scaling | Data layout, prefetch |
| **ğŸŸ¢ Compute-bound** | GPU saturated (good!) | High utilization, stable times | Scale or accept |
| **ğŸŸ£ Throttling** | Power/thermal limits | Clock variance, power drops | Cooling, power limit |

---

<div align="center">

## ğŸ“Š Key Metrics & Formulas

</div>

<table>
<tr>
<td width="33%">

### âš¡ Launch Tax Score

```
launch_tax = Î¼kernel% Ã— rate / 1000
```

| Score | Status |
|-------|--------|
| < 0.3 | âœ… Healthy |
| 0.3-0.7 | âš ï¸ Warning |
| > 0.7 | ğŸ”´ Critical |

</td>
<td width="33%">

### ğŸ”€ Kernel Amplification Ratio

```
KAR = GPU_kernels / ONNX_nodes
```

| KAR | Interpretation |
|-----|----------------|
| â‰ˆ 1.0 | ğŸ† Excellent fusion |
| 2.0-5.0 | âš ï¸ Investigate |
| > 5.0 | ğŸ”´ Severe overhead |

</td>
<td width="33%">

### ğŸ“ˆ GPU Active Ratio

```
active_ratio = Î£kernel_time / wall_time
```

| Ratio | Status |
|-------|--------|
| > 0.9 | ğŸ† GPU-bound |
| 0.7-0.9 | âš ï¸ CPU overhead |
| < 0.7 | ğŸ”´ Launch-bound |

</td>
</tr>
</table>

---

## ğŸ”§ Configuration

### Model Registry (`configs/models.yaml`)

```yaml
models:
  resnet50:
    path: "models/resnet50.onnx"
    input_shapes:
      input: [1, 3, 224, 224]
    dtype: float16
    warmup: 10
    iterations: 100

  bert-base:
    path: "models/bert-base.onnx"
    input_shapes:
      input_ids: [1, 128]
      attention_mask: [1, 128]
    dtype: int64
    warmup: 5
    iterations: 50
```

### Backend Configuration (`configs/backends.yaml`)

```yaml
backends:
  migraphx:
    provider: "MIGraphXExecutionProvider"
    device_id: 0
    fp16_enable: true
    
  cpu:
    provider: "CPUExecutionProvider"
    intra_op_threads: 4
    inter_op_threads: 2
```

---

<div align="center">

## ğŸ’¡ Example Output

</div>

<table>
<tr>
<td width="50%">

### ğŸš¨ Regression Verdict

```json
{
  "regression": true,
  "severity": "high",
  "confidence": 0.92,
  "latency_delta_pct": 18.3,
  "suspected_cause": "launch-bound",
  "evidence": {
    "kernel_launch_count_delta": "+67%",
    "avg_kernel_duration_delta": "-35%",
    "cpu_overhead_delta": "+22%"
  },
  "recommendation": "Investigate graph partitioning. Consider operator fusion."
}
```

</td>
<td width="50%">

### ğŸ¯ Bottleneck Classification

```json
{
  "bottleneck_class": "launch-bound",
  "confidence": 0.87,
  "top_evidence": [
    {"signal": "microkernel_pct", "value": 0.73, "weight": 0.35},
    {"signal": "kernel_launch_rate", "value": 12500, "weight": 0.28},
    {"signal": "cpu_overhead_ratio", "value": 0.31, "weight": 0.22}
  ],
  "optimization_priority": ["fusion", "batching", "async_launch"]
}
```

</td>
</tr>
</table>

### ğŸ“Š Sample Report Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    AACO-SIGMA Performance Report                             â•‘
â•‘                    Model: ResNet-50 | Backend: MIGraphX                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  SUMMARY                                                                     â•‘
â•‘  â”œâ”€ Mean Latency:      4.23ms (Â±0.12ms)                                     â•‘
â•‘  â”œâ”€ P99 Latency:       4.67ms                                               â•‘
â•‘  â”œâ”€ Throughput:        236.4 img/s                                          â•‘
â•‘  â””â”€ GPU Utilization:   94.2%                                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  BOTTLENECK ANALYSIS                                                         â•‘
â•‘  â”œâ”€ Classification:    âœ… COMPUTE-BOUND (Optimal)                           â•‘
â•‘  â”œâ”€ Confidence:        0.91                                                  â•‘
â•‘  â”œâ”€ Launch Tax:        0.12 (Healthy)                                       â•‘
â•‘  â””â”€ KAR:               1.3 (Excellent fusion)                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  TOP KERNELS BY TIME                                                         â•‘
â•‘  1. GEMM_fp16         38.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                  â•‘
â•‘  2. Conv2D_nhwc       31.4%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                  â•‘
â•‘  3. BatchNorm         12.1%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                  â•‘
â•‘  4. ReLU               8.3%  â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

<div align="center">

## ğŸ› ï¸ Development

</div>

<table>
<tr>
<td width="50%">

### ğŸ§ª Testing

```bash
# Unit tests (fast)
pytest tests/unit -v

# Integration tests (requires ROCm)
pytest tests/integration -v

# Full coverage report
pytest --cov=aaco --cov-report=html
```

</td>
<td width="50%">

### âœ¨ Code Quality

```bash
# Lint and format (Ruff)
ruff check aaco/ --fix
ruff format aaco/

# Type checking (strict)
mypy aaco/ --strict
```

</td>
</tr>
</table>

---

<div align="center">

## ğŸ“š Documentation

</div>

| ğŸ“– Document | ğŸ“ Description |
|-------------|----------------|
| [ğŸ—ï¸ Architecture](docs/architecture.md) | System design, 12 pillars, data flow |
| [ğŸ”¬ Methodology](docs/methodology.md) | Measurement science, statistical rigor |
| [ğŸ¯ Bottleneck Taxonomy](docs/bottleneck_taxonomy.md) | Classification rules, evidence signals |
| [ğŸ“Š Data Schema](docs/data_schema.md) | Complete schema, Parquet layouts |

---

<div align="center">

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

[![Contributors](https://img.shields.io/github/contributors/SID-Devu/AMD-AI-Compute-Observatory?style=flat-square)](https://github.com/SID-Devu/AMD-AI-Compute-Observatory/graphs/contributors)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://github.com/SID-Devu/AMD-AI-Compute-Observatory/pulls)

</div>

---

<div align="center">

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

</div>

Built with insights from:
- ğŸ”´ **AMD ROCm Team** - Profiling documentation and best practices
- ğŸ§ **Linux Kernel Community** - eBPF and tracing infrastructure
- ğŸ¤– **ONNX Runtime Team** - Execution provider optimization guides
- ğŸ“ **Performance Engineering Community** - Roofline modeling and analysis

---

<div align="center">

## â­ Star History

If you find AACO-SIGMA useful, please consider giving it a star!

[![Star History Chart](https://api.star-history.com/svg?repos=SID-Devu/AMD-AI-Compute-Observatory&type=Date)](https://star-history.com/#SID-Devu/AMD-AI-Compute-Observatory&Date)

</div>

---

<div align="center">

<img src="https://img.shields.io/badge/AMD-ED1C24?style=for-the-badge&logo=amd&logoColor=white" alt="AMD"/>

### **AACO-SIGMA**
#### Model-to-Metal Performance Engineering Platform

<br/>

**ğŸ† The most comprehensive GPU performance observability platform for AMD Instinct**

<br/>

*"Most engineers can run a model. Some can profile.*
*Very few can instrument kernel + GPU + analytics and produce a diagnosis.*
*AACO-SIGMA does it automatically."*

<br/>

---

**Built with â¤ï¸ for the AMD AI community**

[Report Bug](https://github.com/SID-Devu/AMD-AI-Compute-Observatory/issues) Â· [Request Feature](https://github.com/SID-Devu/AMD-AI-Compute-Observatory/issues) Â· [Discussions](https://github.com/SID-Devu/AMD-AI-Compute-Observatory/discussions)

</div>
